import os
import time
import json
import re
import feedparser
import google.generativeai as genai
from newspaper import Article, Config
from supabase import create_client, Client

# ================= é…ç½®åŒºåŸŸ =================
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

RSS_CONFIGS = [
    {
        "category": "ğŸ¤– AI & Tech",
        "url": "https://techcrunch.com/category/artificial-intelligence/feed/"
    },
    {
        "category": "â‚¿ Crypto",
        "url": "https://www.coindesk.com/arc/outboundfeeds/rss/"
    },
    {
        "category": "ğŸ’° Macro & Market", # å®è§‚ä¸å¸‚åœº
        "url": "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=10000664" # CNBC Finance
    },
    {
        "category": "ğŸ’° Macro & Market", 
        "url": "https://feeds.content.dowjones.io/public/rss/mw_topstories" # MarketWatch
    },
    {
        "category": "ğŸ“± Gadgets & Tech", 
        "url": "https://www.theverge.com/rss/index.xml" # The Verge
    }
]

if not GOOGLE_API_KEY or not SUPABASE_KEY:
    raise ValueError("âŒ API Key ç¼ºå¤±")

genai.configure(api_key=GOOGLE_API_KEY)
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
MODEL_NAME = 'gemini-2.0-flash'

# ================= è¾…åŠ©å‡½æ•° =================

def clean_json_text(text):
    """æ¸…ç† AI å¯èƒ½è¿”å›çš„ Markdown æ ¼å¼ç¬¦å·ï¼Œæå–çº¯ JSON"""
    # ç§»é™¤ ```json å’Œ ``` 
    text = re.sub(r'```json\s*', '', text)
    text = re.sub(r'```\s*', '', text)
    return text.strip()

def check_if_exists(url):
    try:
        response = supabase.table("news").select("id").eq("url", url).execute()
        return len(response.data) > 0
    except Exception:
        return False

def get_article_content(url):
    config = Config()
    config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    config.request_timeout = 10
    try:
        article = Article(url, config=config)
        article.download()
        article.parse()
        return article.title, article.text
    except Exception:
        return None, None

def ai_summarize_structured(title, content):
    """
    è®© AI è¿”å›ä¸¥æ ¼çš„ JSON æ ¼å¼
    """
    # å¼ºåˆ¶ AI è¾“å‡º JSON çš„ Prompt
    system_instruction = """
    ä½ æ˜¯ä¸€ä½é‡‘èæ•°æ®åˆ†æå¼•æ“ã€‚ä¸è¦è¾“å‡ºä»»ä½• Markdown æ ¼å¼æˆ–åºŸè¯ã€‚
    è¯·é˜…è¯»æ–°é—»ï¼Œè¿”å›ä¸”ä»…è¿”å›ä¸€ä¸ªç¬¦åˆ Python è§£ææ ‡å‡†çš„ JSON å­—ç¬¦ä¸²ã€‚
    
    JSON ç»“æ„è¦æ±‚ï¼š
    {
        "summary": "30å­—ä»¥å†…çš„ä¸­æ–‡æ ¸å¿ƒæ‘˜è¦",
        "key_stats": "å…³é”®æ•°æ®åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼Œæ¢è¡Œåˆ†éš”ï¼‰ã€‚è¯·ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°æ¯æ¡æ•°æ®èƒŒæ™¯ï¼Œå¹¶å°†æ ¸å¿ƒæ•°å€¼ï¼ˆå¦‚é‡‘é¢ã€ç™¾åˆ†æ¯”ã€æ—¶é—´ç­‰ï¼‰ç”¨åŒå¤§æ‹¬å·åŒ…è£¹ {{...}}ã€‚ä¾‹å¦‚ï¼š'xLightä»ç¾å›½å•†åŠ¡éƒ¨è·å¾—çš„åˆæ­¥äº¤æ˜“é‡‘é¢ä¸Šé™ä¸º {{$1.5äº¿}}'ã€‚ä¸è¦ä½¿ç”¨ 'æ•°å€¼: æè¿°' çš„æ ¼å¼ï¼Œå¿…é¡»æ˜¯å®Œæ•´çš„å¥å­ã€‚",
        "sentiment_score": ä¸€ä¸ªæ•´æ•° (-10 ä»£è¡¨æåº¦åˆ©ç©º, 0 ä»£è¡¨ä¸­æ€§, 10 ä»£è¡¨æåº¦åˆ©å¥½),
        "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3"]
    }
    """
    
    model = genai.GenerativeModel(model_name=MODEL_NAME, system_instruction=system_instruction)
    
    try:
        # æˆªå–å‰ 6000 å­—ç¬¦é˜²æ­¢ Token æº¢å‡º
        response = model.generate_content(f"æ–°é—»æ ‡é¢˜ï¼š{title}\n\nå†…å®¹ï¼š{content[:6000]}")
        raw_text = response.text
        
        # æ¸…ç†å¹¶è§£æ JSON
        json_str = clean_json_text(raw_text)
        data = json.loads(json_str)
        return data
        
    except Exception as e:
        print(f"âŒ JSON è§£æå¤±è´¥: {e}")
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å› Noneï¼Œè·³è¿‡è¿™æ¡æ–°é—»
        return None

# ================= 2. å‡çº§å…¥åº“å‡½æ•° =================
# å¢åŠ  category å‚æ•°
def save_to_supabase(title, url, ai_data, source, category):
    full_summary = f"{ai_data['summary']}\n\n**å…³é”®æ•°æ®:** {ai_data['key_stats']}"
    
    data = {
        "title": title,
        "url": url,
        "content_summary": full_summary,
        "original_source": source,
        "sentiment_score": ai_data['sentiment_score'],
        "tags": ai_data['tags'],
        "category": category  # <--- æ–°å¢è¿™ä¸€è¡Œ
    }
    
    try:
        supabase.table("news").insert(data).execute()
        print(f"âœ… [{category}] å…¥åº“æˆåŠŸ: {title[:15]}...")
    except Exception as e:
        print(f"âŒ å…¥åº“å¤±è´¥: {e}")

# ================= ä¸»å¾ªç¯ =================

def run_pipeline():
    print("ğŸš€ å¯åŠ¨åˆ†é¢‘é“æŠ“å–...")
    
    # éå†æˆ‘ä»¬é…ç½®å¥½çš„å­—å…¸åˆ—è¡¨
    for config in RSS_CONFIGS:
        category = config['category']
        feed_url = config['url']
        
        print(f"\nğŸŒŠ æ­£åœ¨è¯»å–é¢‘é“: {category} ...")
        
        try:
            feed = feedparser.parse(feed_url)
            for entry in feed.entries[:3]: # æ¯ä¸ªæºæŠ“3æ¡ï¼Œä¿æŒè½»é‡
                url = entry.link
                
                if check_if_exists(url):
                    print("   â­ï¸ è·³è¿‡ (å·²å­˜åœ¨)")
                    continue
                
                print("   ğŸ“¥ ä¸‹è½½ä¸­...")
                title, content = get_article_content(url)
                
                if content:
                    print(f"   ğŸ§  AI åˆ†æä¸­ ({category})...")
                    ai_data = ai_summarize_structured(title, content)
                    
                    if ai_data:
                        # ç®€å•çš„æ¥æºåç§°æå–
                        if "cnbc" in feed_url: source = "CNBC"
                        elif "techcrunch" in feed_url: source = "TechCrunch"
                        elif "coindesk" in feed_url: source = "CoinDesk"
                        elif "dowjones" in feed_url: source = "MarketWatch"
                        else: source = "Web"
                        
                        # ä¼ å…¥ category
                        save_to_supabase(title, url, ai_data, source, category)
                        time.sleep(2)
                        
        except Exception as e:
            print(f"âš ï¸ RSS é”™è¯¯: {e}")

if __name__ == "__main__":
    run_pipeline()